# README â€” Step 3: Risk Scoring â†’ Strategy Selection

This README explains how to implement **Step 3** in the AI-driven CI/CD pipeline: converting build and artifact data into a `risk_score` and selecting a deployment strategy (`rolling | canary | blue-green`).

---

## ðŸŽ¯ Goal
- Convert **build-info / artifact metadata** into a **risk_score (0â€“100)**.
- Select the **deployment strategy** + **pace schedule**.
- Ensure the decision is **auditable, versioned, and testable** in shadow mode before enforcement.

---

## ðŸ‘¥ Owners
- **Platform/CI** â†’ pipeline implementation
- **SRE/Release** â†’ policy + runbooks
- **Service owners** â†’ SLOs, criticality labels
- **Security** â†’ vulnerability gating

---

## ðŸ“¦ Deliverables
- `risk-inputs.json` (from Step 2)
- `risk-decision.json` (output of this step)
- Policy files (versioned) + policy registry entry
- Evidence attached to artifact in Artifactory

---

## ðŸ…° Gather & Normalize Inputs
1. Collect `build-info.json` / `risk-inputs.json` from Artifactory.
2. Ensure it contains:
   - Commit SHA, buildId, repo, branch, author
   - Per-platform artifacts + checksums
   - Unit/integration test results (failed, flaky)
   - Coverage delta vs baseline
   - SBOM & dependency changes
   - Static/security scan summary
   - Files changed + LOC changed
   - Historical failure rate
   - Environment targets (arm/linux/windows)
   - Hardware/emulator test results (if available)
3. Add runtime/context signals:
   - Current production traffic/QPS
   - Calendar context (peak vs maintenance window)
   - Service criticality tag
   - Last rollback flag

ðŸ“„ Deliverable: `risk-inputs-for-decision.json`

---

## ðŸ…± Decide Scoring Approach
- **Phase 1 (Heuristic):** weighted formula â†’ immediate rollout; good for shadow.
- **Phase 2 (ML):** model (XGBoost/LightGBM) â†’ predicts probability of failure; heuristic as fallback.

---

## ðŸ…² Heuristic Scoring (Procedure)
- Define features + weights: LOC, files changed, dep bump, coverage delta, test fails, security issues, past failures, hardware penalty, criticality multiplier.
- Compute raw score â†’ normalize to 0â€“100.
- Apply modifiers (criticality factor, platform penalty, coverage bonus).
- Output: `risk_score` + reasoning list.

ðŸ“„ Deliverable: `risk-decision.json` (risk_score, top_contributors, recommended_strategy, suggested_pace)

---

## ðŸ…³ Strategy Mapping
- Buckets:
  - 0â€“30 â†’ Rolling
  - 31â€“70 â†’ Canary
  - 71â€“100 â†’ Blue-Green
- Pace schedules:
  - Rolling â†’ large batch steps
  - Canary â†’ 10 â†’ 25 â†’ 50 â†’ 100 (windowed)
  - Blue-Green â†’ Green validation before cutover
- Overrides:
  - Critical CVE â†’ force Blue-Green
  - DB schema / kernel driver â†’ Blue-Green + manual approval
  - Hotfix â†’ smaller canary + close monitoring
- Per-OS:
  - ARM firmware more conservative
  - Windows drivers +10 risk
  - Linux â†’ default mapping

ðŸ“„ Deliverable: `strategy-mapping-policy.yaml`

---

## ðŸ…´ Parameterizing Thresholds
- Collect historical builds + outcomes.
- Backtest heuristics: compare predictions vs actual failures.
- Tune thresholds to minimize false negatives, keep false positives manageable.
- Define per-service tolerances + required healthy windows.
- Governance: get sign-off before enforcing.

ðŸ“„ Deliverable: `thresholds-and-windows.md`

---

## ðŸ…µ Policy Storage & Versioning
- **Policy-as-code (Git):** store `risk-weights.yaml`, `strategy-mapping-policy.yaml`, `thresholds.yaml`.
- **Policy Registry:** Jenkins pulls from Git or a Policy Service.
- **Audit Trail:** record policy version, decision, evidence in Artifactory.
- **ML Models (if used):** store in MLflow/artifact registry; reference in policy.

ðŸ“„ Deliverable: versioned policy repo + decision-audit records

---

## ðŸ…¶ Jenkins Pipeline Integration
- Add `Decide Strategy` stage after artifact publish:
  - Fetch `risk-inputs.json`
  - Load policy bundle
  - Compute risk_score & strategy
  - Emit `risk-decision.json`
  - Attach to Artifactory & notify Slack
- Branch pipeline to Rolling / Canary / Blue-Green deployment stages.
- Enforce manual approval for high-risk (e.g., score â‰¥85).

ðŸ“„ Deliverable: Jenkins pipeline stage in shadow â†’ enforced

---

## ðŸ…· Shadow, Calibration & Enforcement
- **Shadow mode:** log decisions for 10â€“20 releases.
- **Calibrate:** tune weights/thresholds weekly.
- **Canary enforcement:** enable for subset of services.
- **Full enforcement:** after governance sign-off.

ðŸ“„ Deliverable: shadow reports + enforcement decision

---

## ðŸ…¸ ML Path (Future)
- Collect features (LOC, files, test fails, deps, CVEs, history, author reliability).
- Label releases: 1 = rollback/failure, 0 = stable.
- Train & evaluate ML model â†’ deploy in shadow.
- Always retain heuristic fallback.

ðŸ“„ Deliverable: model registry entry + policy bundle with model version

---

## ðŸ…¹ Validation & Success Criteria
- Every candidate artifact has `risk-decision.json` attached.
- Policy version recorded + auditable.
- Shadow FPR <10% before enforcement.
- Manual approval required for high-risk.
- Per-OS exceptions respected.
- Accuracy improves over 3-month review cycle.

---

## ðŸ…º Immediate Actions (Checklist)
- [ ] Create `risk-inputs.json` template.
- [ ] Initialize policy repo with weights + mapping + thresholds.
- [ ] Add shadow `Decide Strategy` stage in Jenkins.
- [ ] Store decision evidence in Artifactory.
- [ ] Run 10â€“20 shadow runs + calibrate.
- [ ] Review + approve thresholds with SRE/leadership.

---

âœ… With this README, teams can implement Step 3 safely and iteratively, starting with heuristics and progressing to AI-driven strategy selection.

